{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2bf941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import mne\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.utils import to_undirected\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5421ef6f",
   "metadata": {},
   "source": [
    "### Brainstrom, what we can do ?\n",
    "* first, classification\n",
    "* then, try transfer learning ?\n",
    "* more deeply, apply time-frequency analysis\n",
    "    * classification\n",
    "    * transfer learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec63e3a",
   "metadata": {},
   "source": [
    "### some basic funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e190a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    tol_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        ## zero gradient\n",
    "        optimizer.zero_grad()\n",
    "        ## forward pass\n",
    "        out = model.forward(batch.x, batch.edge_index, batch.batch)\n",
    "        ## calculate loss according to output and y\n",
    "        loss = criterion(out, batch.y)\n",
    "        ## backward propagation\n",
    "        loss.backward()\n",
    "        ## do optimization\n",
    "        optimizer.step()\n",
    "        ## accumulate loss\n",
    "        tol_loss += loss.item()\n",
    "    ## return the mean loss    \n",
    "    return tol_loss / len(train_loader)\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    ## no need to do gradient descent in test phase  \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            ## forward pass\n",
    "            out = model.forward(batch.x, batch.edge_index, batch.batch)\n",
    "            prediction = out.argmax(dim = 1)\n",
    "            correct += (prediction == batch.y).sum().item()\n",
    "            total += batch.y.size(0)\n",
    "            \n",
    "        accuracy = correct / total\n",
    "    return  accuracy   \n",
    "\n",
    "def fit(model, train_loader, test_loader, epochs = 200, lr = 0.01):\n",
    "        ## define optimizer and criterion\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "        ## here i choose cross entropy\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "                train_loss = train(model, train_loader, optimizer, criterion)  \n",
    "                test_acc = test(model, test_loader)\n",
    "                print(f'Epoch {epoch:03d}, Train Loss: {train_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        \n",
    "        return test_acc\n",
    "    \n",
    "def use_method(dist_mat, method, thres = 0.05, k = 4):\n",
    "    '''\n",
    "    Choose the method to build adjacency mat\n",
    "    \n",
    "    Args:\n",
    "        dist_mat: matrix; a matrix has been calculated the Euclidean distance\n",
    "        method: str; kkn or thres\n",
    "        \n",
    "    Returns:\n",
    "        adjacency matrix\n",
    "    '''\n",
    "    adj_mat = np.zeros_like(dist_mat)\n",
    "    \n",
    "    if method == 'thres':\n",
    "        # thres will set a threshold for the whole mat, higher →1，lower→0 \n",
    "        adj_mat = np.where(dist_mat <= thres, 1, 0) \n",
    "        \n",
    "    elif method == 'knn':\n",
    "        # knn will find the top nearest 5 channel for each \n",
    "        for i in range(dist_mat.shape[0]):\n",
    "            idx = np.argsort(dist_mat[i])[0: k+1]  # sort in row i\n",
    "            adj_mat[i, idx] = 1  \n",
    "        adj_mat = np.maximum(adj_mat, adj_mat.T)  \n",
    "    return adj_mat  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947fca5c",
   "metadata": {},
   "source": [
    "### build a simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd6de6",
   "metadata": {},
   "source": [
    "#### define CNN first\n",
    "CNN1 → ReLU → CCN2 → ReLU → pool → Linear1 → ReLU → Dropout(0.5) → Linear2 → ReLU → Output Layer（classification）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec59950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialization params\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            Nothing\n",
    "        '''\n",
    "        ## allocate the nn.module\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 4, out_channels = 32, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 3, kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(in_features = 9216, out_features = 9216)\n",
    "        self.fc2 = nn.Linear(in_features = 9216, out_features = 128)\n",
    "        self.fc3 = nn.Linear(in_features = 128, out_features = 3)\n",
    "    \n",
    "    def forawrd(self):\n",
    "        '''\n",
    "        Here is a forward pass\n",
    "        \n",
    "        Args:\n",
    "            x: torch.tensor\n",
    "               Input feature   \n",
    "                   \n",
    "        Returns:\n",
    "            x: torch.tensor\n",
    "               Output of final fully connected layer\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x) \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b02be27",
   "metadata": {},
   "source": [
    "#### what should the input vector look like??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bffdd6",
   "metadata": {},
   "source": [
    "### build a simple GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9db8d3",
   "metadata": {},
   "source": [
    "####  define GCN first\n",
    "* GCN1 → ReLU → GCN2 → ReLU → meanpool → Linear1 → ReLU → Linear2 → ReLU → Output Layer（classification）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c24ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, fc_hidden, num_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            in_channels: dimension of input\n",
    "            hidden_channels: numbers of hidden_layer\n",
    "            fc_hidden: dimension of input\n",
    "            num_classes: numbers of classification\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)  \n",
    "        self.fc1 = nn.Linear(hidden_channels, fc_hidden)\n",
    "        self.fc2 = nn.Linear(fc_hidden, fc_hidden)\n",
    "        self.classifier = nn.Linear(fc_hidden, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch=batch)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7bfeb",
   "metadata": {},
   "source": [
    "#### ready for the dataset\n",
    "* channels and sequences\n",
    "\n",
    "    'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3','AF4','AF8', 'F7', 'F5','F3','F1','Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1','FCz','FC2','FC4', 'FC6', 'FT8', 'T7','C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1','CPz','CP2', 'CP4','CP6', 'TP8', 'P7','P5', 'P3', 'P1', 'Pz','P2', 'P4', 'P6', 'P8', 'PO7', 'PO3','POz', 'PO4','PO8', 'O1','Oz','O2', 'F9', 'F10', 'TP9', 'TP10'\n",
    "* After reordering, the sequence for both imagery and video trials is as follows:\n",
    "\n",
    "    reorder = ['sad4', 'sad5', 'sad8', 'dis4', 'dis5', 'dis8', 'fear4', 'fear5', 'fear8', 'neu4', 'neu5', 'neu8', 'joy4', 'joy5', 'joy8', 'ten4', 'ten5', 'ten8', 'ins4', 'ins5', 'ins8']\n",
    "* emotion labels: \n",
    "    * negative(sadness, disgust, fear):             0\n",
    "    * positive(happiness, inspiration, tenderness)：1\n",
    "    * neutral:                                      2\n",
    "\n",
    "* so the reoder labels sequence should be: [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a011c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------------load mne------------------------------##\n",
    "# load biosemi64 electrode layout\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "positions = montage.get_positions()\n",
    "\n",
    "## electrode name and 3-dimensional coordinates\n",
    "ch_pos = positions['ch_pos']\n",
    "\n",
    "df = pd.DataFrame.from_dict(ch_pos, orient = 'index', columns = ['x', 'y','z'])\n",
    "df = df.reset_index().rename(columns = {'index': 'electrode'})\n",
    "# print (df)\n",
    "\n",
    "##------------------------load channels --------------------------##\n",
    "channels = ['Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'F7',\n",
    "            'F5',  'F3',  'F1',  'Fz',  'F2',  'F4',  'F6',  'F8', \n",
    "            'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', \n",
    "            'FT8', 'T7',  'C5',  'C3',  'C1',  'Cz',  'C2',  'C4', \n",
    "            'C6',  'T8',  'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2',\n",
    "            'CP4', 'CP6', 'TP8', 'P7',  'P5',  'P3',  'P1',  'Pz',\n",
    "            'P2',  'P4',  'P6',  'P8',  'PO7', 'PO3', 'POz', 'PO4',\n",
    "            'PO8', 'O1',  'Oz',  'O2',  'F9',  'F10', 'TP9', 'TP10']\n",
    "\n",
    "##-----------------calculate Euclidean distance----------------------##\n",
    "# p1 = np.array([x1, y1, z1])\n",
    "# distance = cdist(mat1, mat2)\n",
    "used_channel = channels[: 64]\n",
    "\n",
    "# build a map \n",
    "coord_map = {ch: ch_pos[ch] for ch in used_channel}\n",
    "coords = np.array([coord_map[ch] for ch in used_channel])\n",
    "\n",
    "# now calculate the distance\n",
    "dist_mat = cdist(coords, coords)\n",
    "# dist_df = pd.DataFrame(dist_mat, index=used_channel, columns=used_channel)\n",
    "dist_tensor = torch.tensor(dist_mat, dtype=torch.float)\n",
    "\n",
    "##-------------------build feature matrix-----------------------------##\n",
    "data = np.load('EEG_data\\sub-01_ses-ima_task-emotion_reorder.npy')\n",
    "data = np.transpose(data, (1, 0, 2))\n",
    "num_trials, num_channels, num_samples = data.shape\n",
    "features = np.zeros((num_trials, num_channels, 4))\n",
    "features[:, :, 0] = np.mean(data, axis=2)\n",
    "features[:, :, 1] = np.std(data, axis=2)\n",
    "features[:, :, 2] = skew(data, axis=2)\n",
    "features[:, :, 3] = kurtosis(data, axis=2)\n",
    "features_tensor = torch.tensor(features, dtype=torch.float) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989e80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adjacency mat\n",
    "adj_mat = torch.tensor(use_method(dist_mat, 'knn', k=5), dtype=torch.float )  \n",
    "\n",
    "## feature mat \n",
    "feature_mat = features_tensor   # feature， Should be the exact value([mean, std, skewness, kurtosis])\n",
    "\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1])  # real emotion \n",
    "\n",
    "# connection\n",
    "edge_index_np = np.array(np.nonzero(adj_mat))\n",
    "edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)\n",
    "# split Data into train_set and test_set\n",
    "input_lst = []\n",
    "for i in range(len(y)):\n",
    "    x = feature_mat[i]\n",
    "    y_i = y[i]\n",
    "    data_i = Data(x=x, edge_index=edge_index.clone(), y=y_i)  ## remember to clone!\n",
    "    input_lst.append(data_i)\n",
    "\n",
    "train_len = int(0.8 * len(input_lst))\n",
    "test_len = len(input_lst) - train_len\n",
    "train_dataset, test_dataset = random_split(input_lst, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb885f",
   "metadata": {},
   "source": [
    "####  now run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f04b0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 155.31it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 388.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 1.1710, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 198.42it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 259.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 1.1536, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 190.32it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 349.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002, Train Loss: 1.0577, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 188.29it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 493.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003, Train Loss: 1.0754, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 213.12it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 343.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004, Train Loss: 1.0037, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 183.20it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 416.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 1.0480, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 229.77it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 307.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006, Train Loss: 0.9468, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 205.46it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 339.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 1.0768, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 197.25it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 370.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008, Train Loss: 1.0394, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4/4 [00:00<00:00, 190.61it/s]\n",
      "Testing: 100%|██████████| 2/2 [00:00<00:00, 328.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 1.0516, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleGCN(in_channels=4, hidden_channels=64, fc_hidden=128, num_classes=3)\n",
    "res_acc = fit(model, train_loader=train_loader, test_loader=test_loader, epochs=10, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e3a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
