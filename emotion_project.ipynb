{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bf941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414013e8",
   "metadata": {},
   "source": [
    "#### data interpretation \n",
    "* 64 channels * 21 trials per type(video/imagine) * 6000(guess sampling frequency is 0.01)\n",
    "* reorder = ['sad4', 'sad5', 'sad8', 'dis4', 'dis5', 'dis8', 'fear4', 'fear5', 'fear8', 'neu4', 'neu5', 'neu8', 'joy4', 'joy5', 'joy8', 'ten4', 'ten5', 'ten8', 'ins4', 'ins5', 'ins8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecce8617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 21, 6000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('EEG_data\\sub-01_ses-ima_task-emotion_reorder.npy')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5421ef6f",
   "metadata": {},
   "source": [
    "### Brainstrom, what we can do ?\n",
    "* first, classification\n",
    "* then, try transfer learning ?\n",
    "* more deeply, apply time-frequency analysis\n",
    "    * classification\n",
    "    * transfer learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec63e3a",
   "metadata": {},
   "source": [
    "#### some basic funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e190a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    tol_loss = 0\n",
    "    \n",
    "    for batch in  train_loader:\n",
    "        ## zero gradient\n",
    "        optimizer.zero_grad()\n",
    "        ## forward pass\n",
    "        out = model.forward(batch.x, batch.edge_index, batch.batch)\n",
    "        ## calculate loss according to output and y\n",
    "        loss = criterion(out, batch.y)\n",
    "        ## backward propagation\n",
    "        loss.backward()\n",
    "        ## do optimization\n",
    "        optimizer.step()\n",
    "        ## accumulate loss\n",
    "        tol_loss += loss.item()\n",
    "    ## return the mean loss    \n",
    "    return tol_loss / len(train_loader)\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    ## no need to do gradient descent in test phase  \n",
    "    with torch.no_grad():\n",
    "        for batch in  test_loader:\n",
    "            ## forward pass\n",
    "            out = model.forward(batch.x, batch.edge_index, batch.batch)\n",
    "            prediction = out.argmax(dim = 1)\n",
    "            correct += (prediction == batch.y).sum().item()\n",
    "            total += batch.y.size(0)\n",
    "            \n",
    "        accuracy = correct / total\n",
    "    return  accuracy   \n",
    "\n",
    "def fit(model, train_loader, test_loader, epochs = 200, lr = 0.01):\n",
    "        ## define optimizer and criterion\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "        ## here i choose cross entropy\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "                train_loss = train(train_loader, optimizer, criterion)  \n",
    "                test_acc = test(test_loader)\n",
    "                print(f'Epoch {epoch:03d}, Train Loss: {train_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        \n",
    "        return test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947fca5c",
   "metadata": {},
   "source": [
    "#### build a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec59950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialization params\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            Nothing\n",
    "        '''\n",
    "        ## allocate the nn.module\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 3, kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(in_features = 9216, out_features = 128)\n",
    "        self.fc2 = nn.Linear(in_features = 128, out_features = 2)\n",
    "    \n",
    "    def forawrd(self):\n",
    "        '''\n",
    "        Here is a forward pass\n",
    "        \n",
    "        Args:\n",
    "            x: torch.tensor\n",
    "               Input feature   \n",
    "                   \n",
    "        Returns:\n",
    "            x: torch.tensor\n",
    "               Output of final fully connected layer\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        return x\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bffdd6",
   "metadata": {},
   "source": [
    "### build a simple GCN\n",
    "* GCN1 → ReLU → GCN2 → ReLU → meanpool → Linear1 → ReLU → Linear2 → ReLU → Output Layer（classification）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9db8d3",
   "metadata": {},
   "source": [
    "####  define GCN first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c24ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, fc_hidden, num_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            in_channels: dimension of input\n",
    "            hidden_channels: numbers of hidden_layer\n",
    "            fc_hidden: dimension of input\n",
    "            num_classes: numbers of classification\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)  \n",
    "        self.fc1 = nn.Linear(hidden_channels, fc_hidden)\n",
    "        self.fc2 = nn.Linear(fc_hidden, fc_hidden)\n",
    "        self.classifier = nn.Linear(fc_hidden, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch=batch)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def train(self, train_loader, optimizer, criterion):\n",
    "        self.train()\n",
    "        tol_loss = 0\n",
    "        \n",
    "        for batch in  train_loader:\n",
    "            ## zero gradient\n",
    "            optimizer.zero_grad()\n",
    "            ## forward pass\n",
    "            out = self.forward(batch.x, batch.edge_index, batch.batch)\n",
    "            ## calculate loss according to output and y\n",
    "            loss = criterion(out, batch.y)\n",
    "            ## backward propagation\n",
    "            loss.backward()\n",
    "            ## do optimization\n",
    "            optimizer.step()\n",
    "            ## accumulate loss\n",
    "            tol_loss += loss.item()\n",
    "        ## return the mean loss    \n",
    "        return tol_loss / len(train_loader)\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        ## no need to do gradient descent in test phase  \n",
    "        with torch.no_grad():\n",
    "            for batch in  test_loader:\n",
    "                ## forward pass\n",
    "                out = self.forward(batch.x, batch.edge_index, batch.batch)\n",
    "                prediction = out.argmax(dim = 1)\n",
    "                correct += (prediction == batch.y).sum().item()\n",
    "                total += batch.y.size(0)\n",
    "                \n",
    "            accuracy = correct / total\n",
    "        return  accuracy   \n",
    "    \n",
    "    def fit(self, train_loader, test_loader, epochs = 200, lr = 0.01):\n",
    "            ## define optimizer and criterion\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr = lr)\n",
    "            ## here i choose cross entropy\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                  train_loss = self.train(train_loader, optimizer, criterion)  \n",
    "                  test_acc = self.test(test_loader)\n",
    "                  print(f'Epoch {epoch:03d}, Train Loss: {train_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "            \n",
    "            return test_acc\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7bfeb",
   "metadata": {},
   "source": [
    "#### ready for the dataset\n",
    "* channels and sequences\n",
    "* 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3','AF4','AF8', 'F7', 'F5','F3','F1','Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1','FCz','FC2','FC4', 'FC6', 'FT8', 'T7','C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1','CPz','CP2', 'CP4','CP6', 'TP8', 'P7','P5', 'P3', 'P1', 'Pz','P2', 'P4', 'P6', 'P8', 'PO7', 'PO3','POz', 'PO4','PO8', 'O1','Oz','O2', 'F9', 'F10', 'TP9', 'TP10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 15       ## actually it is 64       \n",
    "num_features = 4        \n",
    "num_edges = 31        \n",
    "\n",
    "x = torch.randn((num_channels, num_features))   # feature， Should be the exact calue([mean, std, skewness, kurtosis])\n",
    "y = torch.tensor([2])                           # real emotion \n",
    "\n",
    "# create connection （no-direction）\n",
    "## i only use 15 channels, or the matrix would be too long for me to write....\n",
    "edge_index = torch.tensor([\n",
    "    [0, 1, 1, 2, 2, 3, 3, 4, 5 , 6, 6, 7, 7, 8, 8, 9, 9, 9,  10, 10, 11, 11, 12, 12, 13, 13, 13, 14, 14, 15, 15],  # start node\n",
    "    [1, 0, 2, 1, 6, 0, 7, 9, 13, 2, 15,3, 8, 7, 9, 4, 8, 10, 9,  11, 10, 12, 11, 13, 12, 5,  14, 13, 15, 14, 6]    # goal node\n",
    "], dtype=torch.long)\n",
    "\n",
    "# build Data \n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb885f",
   "metadata": {},
   "source": [
    "####  now run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGCN(in_channels=3, hidden_channels=64, fc_hidden=128, num_classes=6)\n",
    "res_acc = model.fit(train_loader='', test_loader='', epochs=50, lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
