{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bf941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import mne\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "from torch_geometric.utils import to_undirected\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "from utils.models import *\n",
    "from utils.functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55030b9",
   "metadata": {},
   "source": [
    "#### ready for the dataset\n",
    "* channels and sequences\n",
    "\n",
    "    'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3','AF4','AF8', 'F7', 'F5','F3','F1','Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1','FCz','FC2','FC4', 'FC6', 'FT8', 'T7','C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1','CPz','CP2', 'CP4','CP6', 'TP8', 'P7','P5', 'P3', 'P1', 'Pz','P2', 'P4', 'P6', 'P8', 'PO7', 'PO3','POz', 'PO4','PO8', 'O1','Oz','O2', 'F9', 'F10', 'TP9', 'TP10'\n",
    "* After reordering, the sequence for both imagery and video trials is as follows:\n",
    "\n",
    "    reorder = ['sad4', 'sad5', 'sad8', 'dis4', 'dis5', 'dis8', 'fear4', 'fear5', 'fear8', 'neu4', 'neu5', 'neu8', 'joy4', 'joy5', 'joy8', 'ten4', 'ten5', 'ten8', 'ins4', 'ins5', 'ins8']\n",
    "* emotion labels: \n",
    "    * negative(sadness, disgust, fear):             0\n",
    "    * positive(happiness, inspiration, tenderness)：1\n",
    "    * neutral:                                      2\n",
    "\n",
    "* so the reoder labels sequence should be: [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1202b94",
   "metadata": {},
   "source": [
    "#### load coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------------load mne------------------------------##\n",
    "# load biosemi64 electrode layout\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "positions = montage.get_positions()\n",
    "\n",
    "## electrode name and 3-dimensional coordinates\n",
    "ch_pos = positions['ch_pos']\n",
    "\n",
    "df = pd.DataFrame.from_dict(ch_pos, orient = 'index', columns = ['x', 'y','z'])\n",
    "df = df.reset_index().rename(columns = {'index': 'electrode'})\n",
    "# print (df)\n",
    "\n",
    "##------------------------load channels --------------------------##\n",
    "channels = ['Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'F7',\n",
    "            'F5',  'F3',  'F1',  'Fz',  'F2',  'F4',  'F6',  'F8', \n",
    "            'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', \n",
    "            'FT8', 'T7',  'C5',  'C3',  'C1',  'Cz',  'C2',  'C4', \n",
    "            'C6',  'T8',  'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2',\n",
    "            'CP4', 'CP6', 'TP8', 'P7',  'P5',  'P3',  'P1',  'Pz',\n",
    "            'P2',  'P4',  'P6',  'P8',  'PO7', 'PO3', 'POz', 'PO4',\n",
    "            'PO8', 'O1',  'Oz',  'O2',  'F9',  'F10', 'TP9', 'TP10']\n",
    "\n",
    "##-----------------calculate Euclidean distance----------------------##\n",
    "# p1 = np.array([x1, y1, z1])\n",
    "# distance = cdist(mat1, mat2)\n",
    "used_channel = channels[: 64]\n",
    "\n",
    "# build a map \n",
    "coord_map = {ch: ch_pos[ch] for ch in used_channel}\n",
    "coords = np.array([coord_map[ch] for ch in used_channel])\n",
    "\n",
    "# now calculate the distance\n",
    "dist_mat = cdist(coords, coords)\n",
    "\n",
    "# dist_df = pd.DataFrame(dist_mat, index=used_channel, columns=used_channel)\n",
    "dist_tensor = torch.tensor(dist_mat, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33045295",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c562e",
   "metadata": {},
   "source": [
    "#### 1. prepare datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_pth = r'EEG_data\\reordered'\n",
    "all_data = []\n",
    "all_labels = []\n",
    "len_data = len(os.listdir(basic_pth))\n",
    "\n",
    "def get_labels_for_subject(num0, num1, num2):\n",
    "    return np.array([0]*num0 + [2]*num2 + [1]*num1)\n",
    "\n",
    "for i in range(1, len_data+1):\n",
    "    data = np.load(f'{basic_pth}\\sub-{i:02d}_ses-ima_task-emotion_reorder.npy')\n",
    "    data = np.transpose(data, (1, 0, 2))\n",
    "    label = get_labels_for_subject(9, 3, 9) \n",
    "    \n",
    "    all_data.append(data)\n",
    "    all_labels.append(label)\n",
    "\n",
    "\n",
    "## concat data \n",
    "data = torch.tensor(np.concatenate(all_data, axis=0), dtype=torch.float)      # shape: [21*40=840, 64, 6000]\n",
    "labels = torch.tensor(np.concatenate(all_labels, axis=0),dtype=torch.long )   # shape: [21*40=840]\n",
    "   \n",
    "input_lst = TensorDataset(data, labels)\n",
    "\n",
    "# split Data into train_set and test_set\n",
    "train_len = int(0.8 * len(input_lst))\n",
    "test_len = len(input_lst) - train_len\n",
    "train_dataset, test_dataset = random_split(input_lst, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=21, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed399cd",
   "metadata": {},
   "source": [
    "#### 2. run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49cbb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:14<00:00,  2.19it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 3.6746, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 1.0680, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:14<00:00,  2.28it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002, Train Loss: 1.0500, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.30it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003, Train Loss: 1.0360, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:14<00:00,  2.24it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004, Train Loss: 1.0223, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.41it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 1.0161, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.30it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006, Train Loss: 1.0130, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.35it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 1.0161, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.34it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008, Train Loss: 1.0091, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:13<00:00,  2.39it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 1.0122, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCCN(in_channels = 64, hidden_channels = 128, \n",
    "                  kernel_size=5, out_channel = 3, n_drop = 0.7)\n",
    "\n",
    "res_acc = fit(model, 'CNN', train_loader = train_loader, \n",
    "              test_loader = test_loader, epochs = 10, lr =  1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bffdd6",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e253ea",
   "metadata": {},
   "source": [
    "#### 1. prepare datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a011c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------build feature matrix-----------------------------##\n",
    "basic_pth = r'EEG_data\\reordered'\n",
    "all_data = []\n",
    "len_data = len(os.listdir(basic_pth))\n",
    "\n",
    "for i in range(1, len_data+1):\n",
    "    data = np.load(f'{basic_pth}\\sub-{i:02d}_ses-ima_task-emotion_reorder.npy')\n",
    "    data = np.transpose(data, (1, 0, 2))\n",
    "    \n",
    "    all_data.append(data)\n",
    "\n",
    "## concat data \n",
    "data = np.concatenate(all_data, axis=0)  # [840, 64, 6000]\n",
    "num_trials, num_channels, num_samples = data.shape\n",
    "\n",
    "features = np.zeros((num_trials, num_channels, 4))\n",
    "features[:, :, 0] = np.mean(data, axis=2)\n",
    "features[:, :, 1] = np.std(data, axis=2)\n",
    "features[:, :, 2] = skew(data, axis=2)\n",
    "features[:, :, 3] = kurtosis(data, axis=2)\n",
    "features_tensor = torch.tensor(features, dtype=torch.float) \n",
    "\n",
    "## adjacency mat\n",
    "adj_mat = torch.tensor(use_method(dist_mat, 'knn', k=5), dtype=torch.float )  \n",
    "\n",
    "## feature mat \n",
    "feature_mat = features_tensor \n",
    "\n",
    "## true emotion labels\n",
    "y = torch.tensor(([0]*9 + [2]*3 + [1]*9) * 40).long() \n",
    "\n",
    "# connection edge\n",
    "edge_index_np = np.array(np.nonzero(adj_mat))\n",
    "edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "989e80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Data into train_set and test_set\n",
    "input_lst = []\n",
    "for i in range(len(y)):\n",
    "    x = feature_mat[i]\n",
    "    y_i = y[i]\n",
    "    data_i = Data(x=x, edge_index=edge_index.clone(), y=y_i)  ## remember to clone!\n",
    "    input_lst.append(data_i)\n",
    "\n",
    "train_len = int(0.8 * len(input_lst))\n",
    "test_len = len(input_lst) - train_len\n",
    "train_dataset, test_dataset = random_split(input_lst, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 21, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb885f",
   "metadata": {},
   "source": [
    "####  2. now run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 38.94it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 111.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 1.0591, Test Acc: 0.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 56.12it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 125.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 1.0410, Test Acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 55.26it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 125.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002, Train Loss: 1.0576, Test Acc: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 60.53it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 130.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003, Train Loss: 1.0360, Test Acc: 0.3869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 56.78it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 136.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004, Train Loss: 1.0173, Test Acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 57.94it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 127.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 1.0394, Test Acc: 0.3988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 52.28it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 117.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006, Train Loss: 1.0211, Test Acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 56.13it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 117.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 1.0230, Test Acc: 0.3988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 51.72it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 116.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008, Train Loss: 1.0051, Test Acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 32/32 [00:00<00:00, 55.88it/s]\n",
      "Testing: 100%|██████████| 8/8 [00:00<00:00, 129.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 1.0290, Test Acc: 0.4107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleGCN(in_channels = 4, hidden_channels = 256,\n",
    "                  fc_hidden = 512, num_classes = 3, n_drop = 0.7)\n",
    "res_acc = fit(model, 'GCN', train_loader = train_loader, \n",
    "              test_loader = test_loader, epochs = 10, lr = 1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1a079",
   "metadata": {},
   "source": [
    "### CNN(output feature) + GCN(input feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5366c",
   "metadata": {},
   "source": [
    "#### 1. prepare datum (from CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a93ef0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_pth = r'EEG_data\\reordered'\n",
    "all_data = []\n",
    "all_labels = []\n",
    "len_data = len(os.listdir(basic_pth))\n",
    "\n",
    "def get_labels_for_subject(num0, num1, num2):\n",
    "    return np.array([0]*num0 + [2]*num2 + [1]*num1)\n",
    "\n",
    "for i in range(1, len_data+1):\n",
    "    data = np.load(f'{basic_pth}\\sub-{i:02d}_ses-ima_task-emotion_reorder.npy')\n",
    "    data = np.transpose(data, (1, 0, 2))\n",
    "    label = get_labels_for_subject(9, 3, 9) \n",
    "    \n",
    "    all_data.append(data)\n",
    "    all_labels.append(label)\n",
    "\n",
    "## concat data \n",
    "data = torch.tensor(np.concatenate(all_data, axis=0), dtype=torch.float) \n",
    "labels = torch.tensor(np.concatenate(all_labels, axis=0),dtype=torch.long )   # shape: [21*40=840]\n",
    "\n",
    "batch_size, n_channels, seq_len = data.shape\n",
    "\n",
    "# 2. reshape \n",
    "data_reshaped = data.reshape(batch_size * n_channels, 1, seq_len)\n",
    "\n",
    "# 3. expand label\n",
    "y_expanded = labels.unsqueeze(1).repeat(1, n_channels).reshape(-1)\n",
    "\n",
    "# 4. build Dataset and Loader\n",
    "input_lst = TensorDataset(data_reshaped, y_expanded)\n",
    "loader = DataLoader(input_lst, batch_size=21, shuffle=False)\n",
    "\n",
    "# 5. define model\n",
    "model = SimpleCCN(in_channels=1, hidden_channels=64, kernel_size=5, out_channel=4, n_drop=0.5)\n",
    "\n",
    "# 6. generate feature\n",
    "def generate_fea(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            out = model(inputs)\n",
    "            prediction = nn.functional.softmax(out, dim=1)\n",
    "            preds.append(prediction)\n",
    "    return torch.cat(preds, dim=0)\n",
    "\n",
    "features = generate_fea(model, loader)  # (21*64*40, 4)\n",
    "CNNfeature_mat = features.reshape(batch_size, n_channels, -1)  # (21, 64, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb8331",
   "metadata": {},
   "source": [
    "#### 2. into GNN format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "098ee1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adjacency mat\n",
    "adj_mat = torch.tensor(use_method(dist_mat, 'knn', k=5), dtype=torch.float )  \n",
    "\n",
    "## feature mat \n",
    "feature_mat = CNNfeature_mat   # feature， Should be the exact value([mean, std, skewness, kurtosis])\n",
    "\n",
    "## true emotion labels\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
    "\n",
    "# connection edge\n",
    "edge_index_np = np.array(np.nonzero(adj_mat))\n",
    "edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccd71138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Data into train_set and test_set\n",
    "input_lst = []\n",
    "for i in range(len(y)):\n",
    "    x = feature_mat[i]\n",
    "    y_i = y[i]\n",
    "    data_i = Data(x=x, edge_index=edge_index.clone(), y=y_i)  ## remember to clone!\n",
    "    input_lst.append(data_i)\n",
    "\n",
    "train_len = int(0.8 * len(input_lst))\n",
    "test_len = len(input_lst) - train_len\n",
    "train_dataset, test_dataset = random_split(input_lst, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ef777",
   "metadata": {},
   "source": [
    "#### 3. run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "420e0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 77.29it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 172.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 1.0940, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 89.10it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 214.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 1.0901, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 69.74it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 156.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002, Train Loss: 1.0880, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 68.71it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 160.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003, Train Loss: 1.0926, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 74.32it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 165.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004, Train Loss: 1.0855, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 73.99it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 182.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 1.0827, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 88.07it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 202.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006, Train Loss: 1.0801, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 85.99it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 173.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 1.0786, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 72.41it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 185.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008, Train Loss: 1.0810, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 83.09it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 211.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 1.0778, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimpleGCN(in_channels = 4, hidden_channels = 256, \n",
    "                  fc_hidden = 512, num_classes = 3, n_drop = 0.7)\n",
    "\n",
    "res_acc = fit(model, 'GCN', train_loader = train_loader, \n",
    "              test_loader = test_loader, epochs = 10, lr = 1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c68fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
