{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2bf941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import mne\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "from torch_geometric.utils import to_undirected\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "from utils.models import *\n",
    "from utils.functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55030b9",
   "metadata": {},
   "source": [
    "#### ready for the dataset\n",
    "* channels and sequences\n",
    "\n",
    "    'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3','AF4','AF8', 'F7', 'F5','F3','F1','Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1','FCz','FC2','FC4', 'FC6', 'FT8', 'T7','C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1','CPz','CP2', 'CP4','CP6', 'TP8', 'P7','P5', 'P3', 'P1', 'Pz','P2', 'P4', 'P6', 'P8', 'PO7', 'PO3','POz', 'PO4','PO8', 'O1','Oz','O2', 'F9', 'F10', 'TP9', 'TP10'\n",
    "* After reordering, the sequence for both imagery and video trials is as follows:\n",
    "\n",
    "    reorder = ['sad4', 'sad5', 'sad8', 'dis4', 'dis5', 'dis8', 'fear4', 'fear5', 'fear8', 'neu4', 'neu5', 'neu8', 'joy4', 'joy5', 'joy8', 'ten4', 'ten5', 'ten8', 'ins4', 'ins5', 'ins8']\n",
    "* emotion labels: \n",
    "    * negative(sadness, disgust, fear):             0\n",
    "    * positive(happiness, inspiration, tenderness)：1\n",
    "    * neutral:                                      2\n",
    "\n",
    "* so the reoder labels sequence should be: [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa69eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------------load mne------------------------------##\n",
    "# load biosemi64 electrode layout\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "positions = montage.get_positions()\n",
    "\n",
    "## electrode name and 3-dimensional coordinates\n",
    "ch_pos = positions['ch_pos']\n",
    "\n",
    "df = pd.DataFrame.from_dict(ch_pos, orient = 'index', columns = ['x', 'y','z'])\n",
    "df = df.reset_index().rename(columns = {'index': 'electrode'})\n",
    "# print (df)\n",
    "\n",
    "##------------------------load channels --------------------------##\n",
    "channels = ['Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'F7',\n",
    "            'F5',  'F3',  'F1',  'Fz',  'F2',  'F4',  'F6',  'F8', \n",
    "            'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', \n",
    "            'FT8', 'T7',  'C5',  'C3',  'C1',  'Cz',  'C2',  'C4', \n",
    "            'C6',  'T8',  'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2',\n",
    "            'CP4', 'CP6', 'TP8', 'P7',  'P5',  'P3',  'P1',  'Pz',\n",
    "            'P2',  'P4',  'P6',  'P8',  'PO7', 'PO3', 'POz', 'PO4',\n",
    "            'PO8', 'O1',  'Oz',  'O2',  'F9',  'F10', 'TP9', 'TP10']\n",
    "\n",
    "##-----------------calculate Euclidean distance----------------------##\n",
    "# p1 = np.array([x1, y1, z1])\n",
    "# distance = cdist(mat1, mat2)\n",
    "used_channel = channels[: 64]\n",
    "\n",
    "# build a map \n",
    "coord_map = {ch: ch_pos[ch] for ch in used_channel}\n",
    "coords = np.array([coord_map[ch] for ch in used_channel])\n",
    "\n",
    "# now calculate the distance\n",
    "dist_mat = cdist(coords, coords)\n",
    "\n",
    "# dist_df = pd.DataFrame(dist_mat, index=used_channel, columns=used_channel)\n",
    "dist_tensor = torch.tensor(dist_mat, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33045295",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c562e",
   "metadata": {},
   "source": [
    "#### 1. prepare datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ad38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('EEG_data\\sub-01_ses-ima_task-emotion_reorder.npy')\n",
    "data = np.transpose(data, (1, 0, 2)) # (bacth, channels, time sequence)\n",
    "data = torch.tensor(data, dtype=torch.float )\n",
    "\n",
    "## labels\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
    "\n",
    "input_lst = TensorDataset(data, y)  \n",
    "\n",
    "# split Data into train_set and test_set\n",
    "train_len = int(0.8 * len(input_lst))\n",
    "test_len = len(input_lst) - train_len\n",
    "train_dataset, test_dataset = random_split(input_lst, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=21, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed399cd",
   "metadata": {},
   "source": [
    "#### 2. run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49cbb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 36.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 1.1844, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 41.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 13.1088, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 45.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002, Train Loss: 11.3628, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 29.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003, Train Loss: 0.1430, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 40.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004, Train Loss: 2.1686, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 46.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 0.1520, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 41.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006, Train Loss: 0.5334, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 47.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 0.0745, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 40.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008, Train Loss: 0.0811, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00, 40.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 0.0372, Test Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCCN(in_channels = 64, hidden_channels = 128, \n",
    "                  kernel_size=5, out_channel = 3, n_drop = 0.5)\n",
    "\n",
    "res_acc = fit(model, 'CNN', train_loader = train_loader, \n",
    "              test_loader = test_loader, epochs = 10, lr = 0.5 * 1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bffdd6",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e253ea",
   "metadata": {},
   "source": [
    "#### 1. prepare datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a011c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------build feature matrix-----------------------------##\n",
    "data = np.load('EEG_data\\sub-01_ses-ima_task-emotion_reorder.npy')\n",
    "data = np.transpose(data, (1, 0, 2))\n",
    "num_trials, num_channels, num_samples = data.shape\n",
    "features = np.zeros((num_trials, num_channels, 4))\n",
    "features[:, :, 0] = np.mean(data, axis=2)\n",
    "features[:, :, 1] = np.std(data, axis=2)\n",
    "features[:, :, 2] = skew(data, axis=2)\n",
    "features[:, :, 3] = kurtosis(data, axis=2)\n",
    "features_tensor = torch.tensor(features, dtype=torch.float) \n",
    "\n",
    "## adjacency mat\n",
    "adj_mat = torch.tensor(use_method(dist_mat, 'knn', k=5), dtype=torch.float )  \n",
    "\n",
    "## feature mat \n",
    "feature_mat = features_tensor   # feature， Should be the exact value([mean, std, skewness, kurtosis])\n",
    "\n",
    "## true emotion labels\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
    "\n",
    "# connection edge\n",
    "edge_index_np = np.array(np.nonzero(adj_mat))\n",
    "edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989e80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Data into train_set and test_set\n",
    "input_lst = []\n",
    "for i in range(len(y)):\n",
    "    x = feature_mat[i]\n",
    "    y_i = y[i]\n",
    "    data_i = Data(x=x, edge_index=edge_index.clone(), y=y_i)  ## remember to clone!\n",
    "    input_lst.append(data_i)\n",
    "\n",
    "train_len = int(0.8 * len(input_lst))\n",
    "test_len = len(input_lst) - train_len\n",
    "train_dataset, test_dataset = random_split(input_lst, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb885f",
   "metadata": {},
   "source": [
    "####  2. now run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04b0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.54it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 347.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 1.0666, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.03it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 394.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 1.0847, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.14it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 370.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002, Train Loss: 1.1635, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.03it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 435.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003, Train Loss: 1.0701, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 141.95it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 357.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004, Train Loss: 1.0246, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 167.24it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 326.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 1.0347, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.13it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 363.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006, Train Loss: 1.0215, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 180.24it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 371.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 0.9005, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 171.28it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 405.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008, Train Loss: 1.0315, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 151.13it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 167.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 0.9395, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleGCN(in_channels = 4, hidden_channels = 128,\n",
    "                  fc_hidden = 256, num_classes = 3, n_drop = 0.7)\n",
    "res_acc = fit(model, 'GCN', train_loader = train_loader, \n",
    "              test_loader = test_loader, epochs = 10, lr = 1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1a079",
   "metadata": {},
   "source": [
    "### CNN(output feature) + GCN(input feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5366c",
   "metadata": {},
   "source": [
    "#### 1. prepare datum (from CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a93ef0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load datum\n",
    "data = np.load('EEG_data/sub-01_ses-ima_task-emotion_reorder.npy')\n",
    "data = np.transpose(data, (1, 0, 2))  # (21, 64, 6000)\n",
    "data = torch.tensor(data, dtype=torch.float)\n",
    "\n",
    "batch_size, n_channels, seq_len = data.shape\n",
    "\n",
    "# 2. reshape \n",
    "data_reshaped = data.reshape(batch_size * n_channels, 1, seq_len)\n",
    "\n",
    "# 3. expand label\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "y_expanded = y.unsqueeze(1).repeat(1, n_channels).reshape(-1)\n",
    "\n",
    "# 4. build Dataset and Loader\n",
    "input_lst = TensorDataset(data_reshaped, y_expanded)\n",
    "loader = DataLoader(input_lst, batch_size=32, shuffle=False)\n",
    "\n",
    "# 5. define model\n",
    "model = SimpleCCN(in_channels=1, hidden_channels=64, kernel_size=5, out_channel=4, n_drop=0.5)\n",
    "\n",
    "# 6. generate feature\n",
    "def generate_fea(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            out = model(inputs)\n",
    "            prediction = nn.functional.softmax(out, dim=1)\n",
    "            preds.append(prediction)\n",
    "    return torch.cat(preds, dim=0)\n",
    "\n",
    "features = generate_fea(model, loader)  # (21*64, 4)\n",
    "CNNfeature_mat = features.reshape(batch_size, n_channels, -1)  # (21, 64, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb8331",
   "metadata": {},
   "source": [
    "#### 2. into GNN format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "098ee1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adjacency mat\n",
    "adj_mat = torch.tensor(use_method(dist_mat, 'knn', k=5), dtype=torch.float )  \n",
    "\n",
    "## feature mat \n",
    "feature_mat = CNNfeature_mat   # feature， Should be the exact value([mean, std, skewness, kurtosis])\n",
    "\n",
    "## true emotion labels\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]) \n",
    "\n",
    "# connection edge\n",
    "edge_index_np = np.array(np.nonzero(adj_mat))\n",
    "edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccd71138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Data into train_set and test_set\n",
    "input_lst = []\n",
    "for i in range(len(y)):\n",
    "    x = feature_mat[i]\n",
    "    y_i = y[i]\n",
    "    data_i = Data(x=x, edge_index=edge_index.clone(), y=y_i)  ## remember to clone!\n",
    "    input_lst.append(data_i)\n",
    "\n",
    "train_len = int(0.8 * len(input_lst))\n",
    "test_len = len(input_lst) - train_len\n",
    "train_dataset, test_dataset = random_split(input_lst, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ef777",
   "metadata": {},
   "source": [
    "#### 3. run this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "420e0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 125.65it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 236.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 1.0974, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 131.81it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 385.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Train Loss: 1.0340, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 174.83it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 324.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002, Train Loss: 0.9568, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 128.19it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 297.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003, Train Loss: 0.9646, Test Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.28it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 296.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004, Train Loss: 0.9444, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.89it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 350.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 0.8773, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.74it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 325.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006, Train Loss: 0.9512, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.16it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 250.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 0.8871, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 141.36it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 333.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008, Train Loss: 0.9071, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 138.09it/s]\n",
      "Testing: 100%|██████████| 5/5 [00:00<00:00, 349.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 0.9356, Test Acc: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimpleGCN(in_channels = 4, hidden_channels = 128, \n",
    "                  fc_hidden = 256, num_classes = 3, n_drop = 0.5)\n",
    "\n",
    "res_acc = fit(model, 'GCN', train_loader = train_loader, \n",
    "              test_loader = test_loader, epochs = 10, lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c68fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
